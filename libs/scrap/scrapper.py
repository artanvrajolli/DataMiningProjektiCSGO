import requests
from bs4 import BeautifulSoup
import csv
from pathlib import Path
from time import sleep



def get_Result(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36', }
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    tables = soup.find_all(class_='result-con')
    return tables


def get_mapsResult(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36', }
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    Col = soup.find(class_='col-6 col-7-small')
    return Col

Fields = ['Team_1', 'Team_2', 'Team_score_1', 'Team_score_2','map','link',
          'Map_1','Map1_Team1_Score','Map1_Team2_Score',
          'Map_2','Map2_Team1_Score','Map2_Team2_Score',
          'Map_3','Map3_Team1_Score','Map3_Team2_Score']
filename = "../../Table_1.csv"
if not Path(filename).exists():
    with open(filename, 'w', newline='') as csvfile:
        csvwriter = csv.writer(csvfile)
        csvwriter.writerow(Fields)
xOffset = 0
while True:
    tables = get_Result("https://www.hltv.org/results?startDate=all&offset="+str(xOffset))
    if len(tables) == 0:
        print("end of the road")
        break
    xOffset += 100
    sleep(0.15)
    try:
        table_processed = []
        for table in tables:
            # fetch teamename Team1 Team2
            teams_tags = table.find_all(class_='team')
            teams_ntags = [t.get_text() for t in teams_tags]
            # fetch score team1 team2
            score_tags = table.find_all('span')
            score_ntags = [s.get_text() for s in score_tags]
            score_ntags.pop()


            map_text = table.find(class_='map-text').string
            if map_text != "bo3":
                continue

            link_tag = table.find('a')
            link_href = link_tag.get('href')
            sleep(0.15)
            Result_maps = get_mapsResult("https://www.hltv.org"+link_href);
            #mapname class for map
            # results-team-score class ScoreTeam1
            # results-team-score class ScoreTeam2
            teamsScore = Result_maps.find_all(class_='results-team-score')
            mapnames = Result_maps.find_all(class_='mapname')
            i = 0
            outputMapAndScore = []
            while i < len(teamsScore):
                teamsScore[i] = teamsScore[i].string
                if(i % 2 == 0):
                    mapnames[i//2] = mapnames[i//2].string
                    outputMapAndScore.append(mapnames[i//2])
                outputMapAndScore.append(teamsScore[i])
                i += 1


            output_row = teams_ntags + score_ntags + [map_text] + [link_href]+outputMapAndScore
            #[mapnames[0]] + [teamsScore[0]] + [teamsScore[1]] + [mapnames[1]] + [teamsScore[2]] + [teamsScore[3]] + [mapnames[2]] + [teamsScore[4]] + [teamsScore[5]]
            print(output_row)
            table_processed.append(output_row)

        #print(table_processed)
        with open(filename, 'a', newline='') as csvfile:
            csvwriter = csv.writer(csvfile)
            csvwriter.writerows(table_processed)
    except ValueError:

        print("Error on offset:",xOffset,ValueError)














































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































